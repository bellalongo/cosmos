{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import h5py\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "from file_editing import *\n",
    "from period_finding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "cadence = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commaize if not done already\n",
    "csv_filename = 'cnn_data.csv' # m\n",
    "if not exists(csv_filename):\n",
    "    commaize('raw_cnn_data.csv', csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "df = pd.read_csv(csv_filename)\n",
    "df = df[['iau_name', 'i', 'porb', 'porbe']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    name and ingo blah\n",
    "'''\n",
    "def save_data_hdf5(file_name, lightcurve, periodogram, best_period, literature_period, star_name, star_imag, target_length):\n",
    "    # Determine if the period is probable\n",
    "    is_real, cutoff = is_real_period(periodogram, best_period)\n",
    "\n",
    "    # Define folded and binned lightcurve\n",
    "    phase_lightcurve = lightcurve.fold(period=best_period)\n",
    "    bin_value = find_bin_value(phase_lightcurve, 50)\n",
    "    binned_lightcurve = phase_lightcurve.bin(bin_value*u.min) \n",
    "\n",
    "    # Lightcurve data\n",
    "    time = lightcurve.time.value\n",
    "    flux = lightcurve.flux.value\n",
    "\n",
    "    # Pad or truncate the time and flux arrays\n",
    "    if len(time) < target_length:\n",
    "        time = np.pad(time, (0, target_length - len(time)), mode='constant')\n",
    "        flux = np.pad(flux, (0, target_length - len(flux)), mode='constant')\n",
    "    elif len(time) > target_length:\n",
    "        time = time[:target_length]\n",
    "        flux = flux[:target_length]\n",
    "    else:\n",
    "        time = time\n",
    "        flux = flux\n",
    "\n",
    "    # Get the power at the best period\n",
    "    interp_func = interp1d(periodogram.period.value, periodogram.power.value, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "    power_at_best_period = interp_func(best_period)\n",
    "\n",
    "    # Make an lmfit object and fit it\n",
    "    model = lmfit.Model(sine_wave)\n",
    "    params = model.make_params(amplitude=power_at_best_period, frequency=1/best_period, phase=0.0)\n",
    "    result = model.fit(flux, params, x=time)\n",
    "\n",
    "    # Save data to HDF5\n",
    "    with h5py.File(file_name, 'a') as f:\n",
    "        grp = f.create_group(star_name)\n",
    "        grp.create_dataset('periodogram_period', data = periodogram.period.value)\n",
    "        grp.create_dataset('periodogram_power', data = periodogram.power.value)\n",
    "        grp.create_dataset('time', data = time)\n",
    "        grp.create_dataset('flux', data = flux)\n",
    "        grp.create_dataset('binned_phase', data = binned_lightcurve.phase.value)\n",
    "        grp.create_dataset('binned_flux', data = binned_lightcurve.flux.value)\n",
    "        grp.create_dataset('fitted_sine_wave', data = result.best_fit)\n",
    "        grp.create_dataset('residuals', data = flux - result.best_fit)\n",
    "        grp.attrs['star_imag'] = star_imag\n",
    "        grp.attrs['real_label'] = is_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data has already been added\n",
    "if exists('training_data.h5'):\n",
    "    print('File training_data.h5 already exists.')\n",
    "else:\n",
    "    for _, row in tqdm(df.head(2000).iterrows(), desc=\"Processing lightcurves\", total = 2000):\n",
    "        # Pull data for that star\n",
    "        try:\n",
    "            result = lk.search_lightcurve(row['iau_name'], mission = 'TESS')\n",
    "            result_exposures = result.exptime\n",
    "        except Exception as e:\n",
    "            # print(f\"Error for {row['iau_name']}: {e} \\n\")\n",
    "            continue\n",
    "\n",
    "        lightcurve = append_lightcurves(result, result_exposures, cadence)\n",
    "        if not lightcurve: continue # check if there was a result with the cadence needed\n",
    "\n",
    "        # Star data\n",
    "        star_name = 'TIC ' + str(lightcurve.meta['TICID'])\n",
    "        star_imag = row['i']\n",
    "        literature_period = (row['porb']*u.hour).to(u.day).value\n",
    "        \n",
    "        # Get periodogram\n",
    "        periodogram = lightcurve.to_periodogram(oversample_factor = 10, \n",
    "                                                minimum_period = (2*cadence*u.second).to(u.day).value, \n",
    "                                                maximum_period = 14)\n",
    "        \n",
    "        # Determine if the period is probable\n",
    "        best_period = periodogram.period_at_max_power.value \n",
    "\n",
    "        # Save the data\n",
    "        save_data_hdf5('training_data.h5', lightcurve, periodogram, best_period, literature_period, star_name, star_imag, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_data(hdf5_filename):\n",
    "    with h5py.File(hdf5_filename, 'r') as f:\n",
    "        star_names = list(f.keys())\n",
    "        periodogram_periods = []\n",
    "        periodogram_powers = []\n",
    "        times = []\n",
    "        fluxes = []\n",
    "        binned_phases = []\n",
    "        binned_fluxes = []\n",
    "        fitted_sine_waves = []\n",
    "        residuals = []\n",
    "        labels = []\n",
    "        \n",
    "        for star_name in star_names:\n",
    "            group = f[star_name]\n",
    "            periodogram_periods.append(group['periodogram_period'][:])\n",
    "            periodogram_powers.append(group['periodogram_power'][:])\n",
    "            times.append(group['time'][:])\n",
    "            fluxes.append(group['flux'][:])\n",
    "            binned_phases.append(group['binned_phase'][:])\n",
    "            binned_fluxes.append(group['binned_flux'][:])\n",
    "            fitted_sine_waves.append(group['fitted_sine_wave'][:])\n",
    "            residuals.append(group['residuals'][:])\n",
    "            labels.append(group.attrs['real_label'])\n",
    "    \n",
    "    return (periodogram_periods, periodogram_powers, times, fluxes, binned_phases, binned_fluxes, fitted_sine_waves, residuals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "periodogram_periods, periodogram_powers, times, fluxes, binned_phases, binned_fluxes, fitted_sine_waves, residuals, labels = load_data('training_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(periodogram_periods, periodogram_powers, times, fluxes, binned_phases, binned_fluxes, fitted_sine_waves, residuals, labels):\n",
    "    # Ensure all input arrays are numpy arrays\n",
    "    periodogram_periods = np.array(periodogram_periods)\n",
    "    periodogram_powers = np.array(periodogram_powers)\n",
    "    times = np.array(times)\n",
    "    fluxes = np.array(fluxes)\n",
    "    binned_phases = np.array(binned_phases)\n",
    "    binned_fluxes = np.array(binned_fluxes)\n",
    "    fitted_sine_waves = np.array(fitted_sine_waves)\n",
    "    residuals = np.array(residuals)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Ensure all arrays have the same number of samples\n",
    "    n_samples = labels.shape[0]\n",
    "    assert periodogram_periods.shape[0] == n_samples\n",
    "    assert periodogram_powers.shape[0] == n_samples\n",
    "    assert times.shape[0] == n_samples\n",
    "    assert fluxes.shape[0] == n_samples\n",
    "    assert binned_phases.shape[0] == n_samples\n",
    "    assert binned_fluxes.shape[0] == n_samples\n",
    "    assert fitted_sine_waves.shape[0] == n_samples\n",
    "    assert residuals.shape[0] == n_samples\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    periodogram_periods = scaler.fit_transform(periodogram_periods)\n",
    "    periodogram_powers = scaler.fit_transform(periodogram_powers)\n",
    "    times = scaler.fit_transform(times)\n",
    "    fluxes = scaler.fit_transform(fluxes)\n",
    "    binned_phases = scaler.fit_transform(binned_phases)\n",
    "    binned_fluxes = scaler.fit_transform(binned_fluxes)\n",
    "    fitted_sine_waves = scaler.fit_transform(fitted_sine_waves)\n",
    "    residuals = scaler.fit_transform(residuals)\n",
    "    \n",
    "    # Stack the different features into a single tensor\n",
    "    X = np.stack([periodogram_periods, periodogram_powers, times, fluxes, \n",
    "                  binned_phases, binned_fluxes, fitted_sine_waves, residuals], axis=-1)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "X_train, X_val, y_train, y_val = preprocess_data(periodogram_periods, periodogram_powers, times, fluxes, binned_phases, binned_fluxes, fitted_sine_waves, residuals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def create_cnn_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         Conv2D(64, (3, 3), activation='relu'),\n",
    "#         MaxPooling2D((2, 2)),\n",
    "#         Dropout(0.25),\n",
    "#         Flatten(),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dropout(0.5),\n",
    "#         Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pceb_ob_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
